# Defect-Detection-Using-Enhanced-YOLO-Network


In this project I will use an object detector called YOLO (You Only Look Once) to detect defects on metal surfaces such as scratches and patches.
YOLO is pre-trained to detect everyday objects such as cars, person, table etc... The challenge here is to re-train this network to detect
a custom dataset provided which contains images and labels of several defects.



WHAT IS YOLO?

YOLO is a one-shot object detection algorithm and it is one of the fastest algorithms that exist today. One-shot object detection is when the detector has no need for a delegated region proposal network and can predict bounding boxes in images from feature maps in one single pass. It is mostly used in areas where speed is a crucial element without the loss of too much accuracy. As mentioned earlier, CNNs benefit from a lower number of parameters and in the case of YOLOV3 the number of parameters is approximately 59 million. This can be found out by dividing the size of the weights file which is 236.5 megabytes by 4. The third version of YOLO was released in 8 April 2018 (Redmon and Farhadi, 2018). The way YOLO works is it divides an image into an SxS grid of cells and each of the cells is then responsible for creating bounding boxes. The convolutional layers are then responsible for the actual feature extraction. The bounding boxes described enclose the object detected and then YOLO gives a confidence score for the bounding box. Each prediction has five components which are the coordinates of the centre of the box (x,y) and (w,h) which are the width and height of the box. X, Y, W and H are all normalized to a value between 0 and 1. The fifth component is the confidence score. YOLO uses the IOU (Intersection over Union) evaluation metric to calculate the confidence score. 
 
The confidence score is the IOU between the box predicted by YOLO and the box which is exactly where the object to be detected is. Pr(Object) is the probability of the desired object in the grid and IOU is the overlapping rate between the ground truth and the bounding box . A Non-Maximum Suppression (NMS) method is used to remove the bounding boxes that are redundant. 
confidence as Pr(Object)* IOUpredtruth 
Pr(Class|Object) is the probability of the desired object being in a bounding box. To get class specific confidence in each box, Pr(class)*IOU is used. The underlying architecture for YOLO contains 106 layers, 53 layers for the task of detection and another 53 layers for DARKNET-53 which will be mentioned in the coming section. 


DARKNET

The backbone of YOLO is called DARKNET (Redmon, 2016) created by Joseph Redmon, which is a neural network framework written in CUDA and C. Its advantages are that it is quick, slim and easy to work with. YOLOv3 uses a modified version of the original DARKNET-19 which is called DARKNET53 because it has 53 convolutional layers trained on ImageNet , is much deeper than DARKNET19 and composes mainly of3x3 and 1x1 filters with shortcut connections (Redmon and Farhadi, 2016). DARKNET has its own commands and parameters which are used to train, test, calculate accuracy and perform many other operations on the model being worked on. Darknet 53 was also proven (Redmon and Farhadi, 2018) to have better performance than Residual Neural Network (ResNet-101) and it is 1.5 times faster and compared to ResNet152 it has similar performance but is 2 times faster . This thesis uses a slightly modified DARKNET-53 by AlexeyAB (GitHub, n.d.) to allow for training on custom datasets. 
 
 CUSTOM DETECTION
 
 YOLO is a pretrained object detector made so that it is ready to use to detect objects such as tables, cars, chairs and other everyday objects. In this project, an attempt to retrain YOLO on a custom dataset is made. In order to train YOLO on a custom dataset, the source code and hyperparameters must be modified to accompany the required changes in data and number of classes as well as to produce new custom weights. Similar to the original YOLO, the convolutional layers extract the defect features from the images provided which is why YOLO and its backbone, DARKNET-53 are a very good choice for this application. Picking up the features of the defects as best as possible is the most important task for this experiment to work. Retraining YOLOV3 over and over with different modifications in the hyperparameters values is done until the desired results were achieved. 
 
 THE DATASET
 
 The images were obtained from the North-eastern University (NEU) surface database (Song and Yan, 2013), (He et al., 2019) which contained six kinds of defects (rolled-in scale (Rs), patches (Pa), crazing (Cr), pitted surface (Ps), inclusion (In) and scratches (Sc)) with 300 images for each defect (1800 total). Image size was 200*200 pixels with a .bmp format and the images were in grey-scale. The defects in the images vary and are provided in many shapes, sizes, illumination and orientation. The images were already labelled, and the labels contained information such as location and size of the bounding box in an XML format.
 
 
 DATASET PREPARATION
 
 No pre-processing is done on the images since the features to be picked up by the network heavily depend on the details and texture of the metal surface and defects. So, any image modification will alter the textures and features. The only change however is the size of the images since they were too small to begin with (200x200). The images were resized to 608x608 pixels using an online resizing tool (Bulkresizephotos.com, 2019). This had to be done since in the case of YOLO, the image size has to be bigger than the network size otherwise it could cause the network to not be able to detect the defects properly. The network will later on resize the images on its own as its training. The dataset was split 90% training data and 10% testing data. 
 
 HOW THE FILES WORK
 
 In every machine learning application, the dataset plays a role of utmost importance in achieving good results and generalization. As mentioned earlier, the images are from a dataset from NEU database and are already labelled. However, for YOLO the labels need to be in a certain format, and for this a python script was written to perform the following actions: 1) Convert the XML files to TXT files. 2) Pick out the necessary fields from the original labels file and discard of the rest. 3) Give each defect an ID starting from zero. 4) Normalize the given coordinates. This script is compiled to end up with a TXT file containing: “(object-id) (x-centre) (ycentre) (width) (height)”. The object id is the ID of each defect, x-centre and ycentre give the centre of the bounding box while width and height give the size of the bounding box. So, with this, each training image has a bounding box around the defect so YOLO can use it to train. 
 
When training an object detector, it is always good to start from an existing trained model which was trained on very large datasets and then use the weights of this model to train. This is fine even if the trained weights do not contain the objects required in this experiment. This process is called transfer learning. A pretrained model that contains weights trained on ImageNet is used as starting weights so that the network can learn quicker. This is also beneficial since less data will be required which is convenient since the NEU dataset only has 300 images per class before train/test split. Another advantage of transfer learning is convexity (Aytar and Zisserman, 2011). (Shin et al., 2016) have used transfer learning for their model. Their dataset was related to medical images however, they used weights from a pre-trained model on ImageNet to be able to make medical image recognition tasks more accurate. 
 
Next, the source files of YOLO and DARKNET were modified in order to achieve custom object detection. A .data file is created to set the number of classes and to specify the path of the train and test .txt files as well as the .names file which contains the names of each class to be detected and finally the file location of the backup folder where the weights will be saved after training. The train and test txt files contain the path to each and every image in the dataset. The .names class contains the names of the classes to be detected in order of their IDs specified earlier. The most important file in this process is the configuration file which in this experiment is the yolov3.cfg file since the full version of YOLOv3 is used. In this file the number of batches on line 3 and number of subdivisions on line 4 was specified, after that the number of max batches was specified where max-batches=no.of classes*2000 and the number of steps was also specified where steps=80% and 90% of max batches. Next, in each YOLO layer in the .cfg file, the number of classes was specified and then in each convolutional layer just before the YOLO layers, the filters were specified where filter is equal to the number of classes added to the number of bounding box components multiplied by 3. Filters=(classes+5) x3.  
 
With all the files ready and YOLO ready to be trained, Google Colab was used as the main environment to deploy and run DARKNET as well as to train and test the network. Colab offers a single 12GB NVIDIA Tesla K80 GPU which is very convenient since DARKNET is compatible with the NVIDIA drivers and it is written in C and CUDA, and for this cuDNN for CUDA was installed in order to be able to run the training on the GPU. YOLO was left to train for 12000 iterations using 64 batches divided into 64 subdivisions. 
 
The training starts by YOLO showing all 106 layers along with their size as well as the number of filters in each layer. It also shows the process of resizing mentioned earlier where with each layer YOLO resizes the image into smaller dimensions. Next, each iteration is displayed along with some information such as the loss, number of iterations, time for iteration, number of images used so far, the current learning rate which controls how aggressively the network should learn based on the current batch of images. The learning rate starts off high at the beginning since it still has no information, however as the network sees more and more images the learning rate should start to decrease. It must be noted however that in some cases the learning will increase in the beginning and then start to decrease as it learns, this is called the burn in period and is also called warm up. 
 
YOLOV3 uses the sum-squared error between predictions made and the ground truth to calculate loss. The loss function comprises of the classification loss if an object is detected, the classification loss for each cell is the squared error of the class conditional probabilities for each class, the localization loss which measures the errors in the locations and sizes of the predicted boundary box and finally the confidence loss which is a measurement of the objectness of the box.  


RESULTS AND ANALYSIS

YOLO reached an average loss of 0.11 which is supposed to be good, however the network did not converge, the MAP was very low, no detections were made even on training images, true positive and false positive values were almost null and finally, the accuracy for each class was mostly 0.00% which meant more research and changes had to made in order to get better results. The next attempt was to troubleshoot the problem so 4 classes were removed, and then YOLO was left to train for only two classes which had defects easy to detect. After training, the results obtained were about the same, however YOLO was able to detect defects in some images with very low confidence. But obviously, the results were not good considering only two classes were used.  
 
Another trial was attempted where YOLO was left to train for more iterations and the results barely improved. This meant that the number of iterations was not the cause of the bad results and more training is not going to solve this problem. 
The dataset images were 200x200 in size however the network size was 416x416. YOLO has a built-in feature which allows it to resize images on its own in order to get the best out of the training however it was later discovered that this was not working properly since the network size was bigger than the images. After experimenting with resizing the images and resizing the network it was concluded that with a network size of 416x416 and image size of 608x608 the network achieved the best results . There was no stopping there and more improvement was needed so for this the number of batches was lowered from 64 to 24 and the subdivisions from 64 to 8. The use of small batches as opposed to the typical use of large mini batches, was proved to get better generalization and allows for a smaller memory footprint (Masters and Luschi, 2018). There are usually three ways to go about when choosing the batches for training. Batch gradient descent is when all the data is taken to training at once. In this method the model converges slowly with accurate estimates of the error gradient. The second method is the stochastic gradient descent where the model takes one image at a time and updates the parameters after only one training instance. Then there’s the mini batch gradient descent where a certain number of batches is taken during training. A mini batch gradient descent finds balance between the robustness of stochastic gradient descent and the efficiency of batch gradient descent. Smaller batch sizes are noisy, offering a regularizing effect and lower generalization error and makes it easier to fit one batch worth of data in memory. This was by far the best improvement that was done in this experiment. The results were much better, and the network was able to converge and detect defects in all images including test images with high confidence. The network was trained for 20000 iterations however the best results were after 17000 which shows that YOLO was starting to overfit after 17000 iterations . 
 
The results improved tremendously when the network size and images were modified and when the number of batches was lowered. This caused the network to converge faster and obtain good results and detections and achieve a MAP of 70.66 %.  It can be noticed that the MAP suffered a drop because of the average precision of one of the defects which was 24.82%. The area between the detected bounding box and the actual bounding box was 60.42% giving the IOU. Obtaining IOU will in return give the values of true positives and false positives. With true positives (TP), false positives (FP) and false negatives (FN) obtained, the precision, which is the percentage of correct predictions and recall which is how good YOLO could find all the positives can be calculated where precision= TP/(TP+FP) =0.79 and recall=TP/(TP+FN) =0.68. With precision and recall obtained, the F1 score could be calculated which in this case turned out to be 0.73 where F1= 2 x (precision x recall)/ (precision + recall). As mentioned above, the average precision for each class is obtained, this is done by finding the area under the precision-recall curve. The precision-recall curve shows the trade between recall and precision for a certain threshold. Usually, a high area indicates high recall and precision where high precision means a low number of false positives and high recall means a low number of false negatives. With the average precision for each class, the MAP can be calculated which is the average of all the average precisions for all the classes. 
 YOLO detects, localizes and classifies each of the six defects by drawing a bounding box around the defect and displaying the percentage of confidence as well as the time it took for detection. The images used for this demonstration are all test images never seen by the network during training. YOLO was 99% confident that the defect is a pitted surface and it took 81.86 milliseconds for the whole process to be done. It can be observed that gradient boosting has the best accuracy of 92.5%. It must be noted that normally classifiers are not normally the first choice when it comes to object detection and classifications, however in this case (Saurabh, 2018) was only trying to classify the defects rather than detect and localize them in images. Using these classifiers allows for the use of a simple metric system to calculate accuracy which is equal to the number of correctly classified images divided by the total number of input images. When it comes to detectors such as YOLO it is much better to use the MAP metric instead. MAP has many advantages over other metrics like avoiding the “accuracy paradox” which is the accuracy increases even though the model is not actually good. This usually happens when TP < FP. That being said, it hard to compare YOLOv3 with these classifiers since it is not possible to calculate an accuracy value for YOLO. This is because true negatives (TN) are not available to use. True negative is usually ignored and not used when it comes to object detectors because the number of true negatives is infinity since in an image there could be an infinite number of bounding boxes that do not enclose the desired object.  The fully convolutional YOLO received the best results out of the three granted it received major modifications to the layers, the worst of the three was the CNN with only two layers and in between is YOLO presented in this thesis receiving only minor modifications to the hyperparameters of the network. 
 
 	 
As mentioned earlier, in this thesis YOLO is able to provide information about the location and size of the defects. The coordinates of the resulting bounding boxes can be extracted and written to a .txt file and be used to evaluate the quality of the metal sheets. 






